# 21.9 性能调优
- [一、比较各类互斥技术](#一、比较各类互斥技术)
- [二、免锁容器](#二、免锁容器)
- [三、乐观加锁](#三、乐观加锁)
- [四、ReadWriteLock](#四、readwritelock)

在Java SE5的java.util.concurrent类库中存在着数量庞大的用于性能提高的类。当你细读concurrent类库时就会发现很难辨认哪些类适用于常规应用（例如BlockingQueue），而哪些类只适用于提高性能。在本节中，我们将围绕着性能调优探讨某些话题和类。

---

## 一、比较各类互斥技术
既然Java包括老式的synchronized关键字和Java SE5中新的Lock和Atomic类，那么比较这些不同的方式，更多地理解它们各自的价值和适用范围，就会显得很有意义。

比较天真的方式是针对每种方式都执行一个简单的测试，就像下面这样：
```java
package concurrency;
import java.util.concurrent.locks.*;

abstract class Incrementable {
	protected long counter = 0;
	public abstract void increment();
}

class SynchronizingTest extends Incrementable {
	public synchronized void increment() { ++counter; }
}

class LockingTest extends Incrementable {
	private Lock lock = new ReentrantLock();
	public void increment() {
		lock.lock();
		try {
			++counter;
		} finally {
			lock.unlock();
		}
	}
}

public class SimpleMicroBenchmark {
    static long test(Incrementable incr) {
    	long start = System.nanoTime();
    	for(long i = 0; i < 10000000L; i++)
    		incr.increment();
    	return System.nanoTime() - start;
    }
	public static void main(String[] args) {
        long synchTime = test(new SynchronizingTest());
        long lockTime = test(new LockingTest());
        System.out.printf("synchronized: %1$10d\n", synchTime);
        System.out.printf("Lock:         %1$10d\n", lockTime);
        System.out.printf("Lock/synchronized = %1$.3f", 
        		(double)lockTime / (double)synchTime);
	}
} /*Output:
synchronized: 244919117 
Lock: 939098964
Lock/synchronized = 3.834
*///
```
从输出中可以看到，对synchronized方法的调用看起来要比使用ReetrantLock快，这是因为什么呢？

本例演示了所谓的“微基准测试”危险，这个术语通常指在隔离的、脱离上下文环境的情况下对某个特性进行性能测试。当然，你仍旧必须编写测试来验证诸如“Lock比synchronized更快”这样的断言，但是你需要在编写这些测试的时候意识到，在编译过程中和在运行时实际会发生什么。

上面的示例存在着大量的问题。首先也是最重要的是，我们只有在这些互斥存在竞争的情况下，才能看到真正的性能差异，因此必须有多个任务尝试着访问互斥代码区。而在上面的示例中，每个互斥都是由单个的main()线程在隔离的情况下测试的。

其次，当编译器看到synchronized关键字时，有可能会执行特殊的优化，甚至有可能会注意到这个程序是单线程的。编译器甚至可能会识别出counter被递增的次数是固定数量的，因此会预先计算出其结果。不同的编译器和运行时系统在这方面会有所差异，因此很难确切了解将会发生什么，但是我们需要防止编译器去预测结果的可能性。

为了创建有效的测试，我们必须使程序更加复杂。首先我们需要多个任务，但并不只是会修改内部值的任务，还包括读取这些值的任务（否则优化器可以识别出这些值从来都不会被使用）。另外，计算必须足够复杂和不可预测，以使得编译器没有机会执行积极的优化。这可以通过预加载一个大型的随机int数组（预加载可以减少在主循环上调用Random.nextInt()所造成的的影响），并在计算总和时使用它们来实现：
```java
package concurrency;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;
import java.util.*;
import java.util.concurrent.locks.*;

abstract class Accumulator {
	public static long cycles = 50000L;
	// Number of Modifies and Readers during each test:
	private static final int N = 4;
	public static ExecutorService exec = Executors.newFixedThreadPool(N*2);
	private static CyclicBarrier barrier = new CyclicBarrier(N*2 + 1);
	protected volatile int index = 0;
	protected volatile long value = 0;
	protected long duration = 0;
	protected String id = "error";
	protected final static int SIZE = 100000;
	protected static int[] preLoaded = new int[SIZE];
	static {
		// Load the array of random numbers:
		Random rand = new Random(47);
		for(int i = 0; i < SIZE; i++)
			preLoaded[i] = rand.nextInt();
	}
	public abstract void accumulate();
	public abstract long read();
	private class Modifier implements Runnable {
		public void run() {
			for(long i = 0; i < cycles; i++)
				accumulate();
			try {
				barrier.await();
			} catch(Exception e) {
				throw new RuntimeException(e);
			}
		}
	}
	private class Reader implements Runnable {
		private volatile long value;
		public void run() {
			for(long i = 0; i < cycles; i++)
				value = read();
			try {
				barrier.await();
			} catch(Exception e) {
				throw new RuntimeException(e);
			}
		}
	}
	public void timedTest() {
		long start = System.nanoTime();
		for(int i = 0; i < N; i++) {
			exec.execute(new Modifier());
			exec.execute(new Reader());
		}
		try {
			barrier.await();
		} catch(Exception e) {
			throw new RuntimeException(e);
		}
		duration = System.nanoTime() - start;
		System.out.printf("%-13s: %13d\n", id, duration);
	}
	public static void report(Accumulator acc1, Accumulator acc2) {
		System.out.printf("%-22s: %.2f\n", acc1.id + "/" + acc2.id,
				(double)acc1.duration/(double)acc2.duration);
	}
}

class BaseLine extends Accumulator {
	{ id = "BaseLine"; }
	public void accumulate() {
		value += preLoaded[index++];
		if(index >= SIZE) index = 0;
	}
	public long read() { return value; }
}

class SynchronizedTest extends Accumulator {
	{ id = "synchronized"; }
	public synchronized void accumulate() {
		value += preLoaded[index++];
		if(index >= SIZE) index = 0;
	}
	public synchronized long read() {
		return value;
	}
}

class LockTest extends Accumulator {
	{ id = "Lock"; }
	private Lock lock = new ReentrantLock();
	public void accumulate() {
		lock.lock();
		try {
			value += preLoaded[index++];
			if(index >= SIZE) index = 0;
		} finally {
			lock.unlock();
		}
	}
	public long read() {
		lock.lock();
		try {
			return value;
		} finally {
			lock.unlock();
		}
	}
}

class AtomicTest extends Accumulator {
	{ id = "Atomic"; }
	private AtomicInteger index = new AtomicInteger(0);
	private AtomicLong value = new AtomicLong(0);
	public void accumulate() {
		// Oops! Relying on more than one Atomic at
		// a time doesn't work. But it still gives us
		// a performance indicator:
		int i = index.getAndIncrement();
		value.getAndAdd(preLoaded[i]);
		if(++i >= SIZE)
			index.set(0);
	}
	public long read() { return value.get(); }
}

public class SynchronizationComparisons {
    static BaseLine baseLine = new BaseLine();
    static SynchronizedTest synch = new SynchronizedTest();
    static LockTest lock = new LockTest();
    static AtomicTest atomic = new AtomicTest();
    static void test() {
    	System.out.println("===========================");
    	System.out.printf("%-12s : %13d\n", "Cycles", Accumulator.cycles);
    	baseLine.timedTest();
    	synch.timedTest();
    	atomic.timedTest();
    	Accumulator.report(synch, baseLine);
    	Accumulator.report(lock, baseLine);
    	Accumulator.report(atomic, baseLine);
    	Accumulator.report(synch, lock);
    	Accumulator.report(synch, atomic);
    	Accumulator.report(lock, atomic);
    }
	public static void main(String[] args) {
        int iterations = 5;  // Default
        if(args.length > 0)  // Optionally change iterations
        	iterations = new Integer(args[0]);
        // The first time fills the thread pool:
        System.out.println("Warmup");
        baseLine.timedTest();
        // Now the initial test doesn't include the cost
        // of starting the threads for the first time.
        // Produce multiple data points:
        for(int i = 0; i < iterations; i++) {
        	test();
        	Accumulator.cycles *= 2;
        }
        Accumulator.exec.shutdownNow();
	}
} /*Output:
Warmup 
BaseLine : 34237033 
============================ 
Cycles : 50000 
BaseLine : 20966632 
synchronized : 24326555 
Lock : 53669950 
Atomic : 30552487 
synchronized/BaseLine : 1.16 
Lock/BaseLine : 2.56 
Atomic/BaseLine : 1.46 
synchronized/Lock : 0.45 
synchronized/Atomic : 0.79 
Lock/Atomic : 1.76 
============================ 
Cycles : 100000 
BaseLine : 41512818 
synchronized : 43843003 
Lock : 87430386 
Atomic : 51892350 
synchronized/BaseLine : 1.06 
Lock/BaseLine : 2.11 
Atomic/BaseLine : 1.25 
synchronized/Lock : 0.50 
synchronized/Atomic : 0.84 
Lock/Atomic : 1.68 
============================ 
Cycles : 200000 
BaseLine : 80176670 
synchronized : 5455046661 
Lock : 177686829 
Atomic : 101789194 
synchronized/BaseLine : 68.04 
Lock/BaseLine : 2.22 
Atomic/BaseLine : 1.27 
synchronized/Lock : 30.70 
synchronized/Atomic : 53.59 
Lock/Atomic : 1.75 
============================ 
Cycles : 400000 
BaseLine : 160383513 
synchronized : 780052493 
Lock : 362187652 
Atomic : 202030984 
synchronized/BaseLine : 4.86
Lock/BaseLine : 2.26 
Atomic/BaseLine : 1.26 
synchronized/Lock : 2.15 
synchronized/Atomic : 3.86 
Lock/Atomic : 1.79 
============================ 
Cycles : 800000 
BaseLine : 322064955 
synchronized : 336155014 
Lock : 704615531 
Atomic : 393231542 
synchronized/BaseLine : 1.04 
Lock/BaseLine : 2.19 
Atomic/BaseLine : 1.22 
synchronized/Lock : 0.47 
synchronized/Atomic : 0.85 
Lock/Atomic : 1.79 
============================ 
Cycles : 1600000 
BaseLine : 650004120 
synchronized : 52235762925 
Lock : 1419602771 
Atomic : 796950171 
synchronized/BaseLine : 80.36 
Lock/BaseLine : 2.18 
Atomic/BaseLine : 1.23 
synchronized/Lock : 36.80 
synchronized/Atomic : 65.54 
Lock/Atomic : 1.78 
============================ 
Cycles : 3200000 
BaseLine : 1285664519 
synchronized : 96336767661 
Lock : 2846988654 
Atomic : 1590545726 
synchronized/BaseLine : 74.93 
Lock/BaseLine : 2.21 
Atomic/BaseLine : 1.24 
synchronized/Lock : 33.84 
synchronized/Atomic : 60.57 
Lock/Atomic : 1.79
*///
```
这个程序使用了**模版方法**设计模式，将所有共用代码都放置到基类中，并将所有不同的代码隔离在导出类的accumulate()和read()的实现中。在每个导出类SynchronizedTest、LockTest和AtomicTest中，你可以看到accumulate()和read()如何表达了实现互斥现象的不同方式。

在这个程序中，各个任务都是由FixedThreadPool执行的，在执行过程中尝试着在开始时跟踪所有线程的创建，并且在测试过程中防止产生任何额外的开销。为了保险起见，初始测试执行了两次，而第一次的结果被丢弃，因为它包含了初始线程的创建。

程序中必须有一个CyclicBarrier，因为我们希望确保所有的任务在声明每个测试完成之前都已经完成。

每次调用accumulate()时，它都会移动到preLoaded数组的下一个位置（到达数组尾部时再回到开始位置），并将这个位置的随机生成的数字加到value上。多个Modifier和Reader任务提供了在Accumulator对象上的竞争。

注意，在AtomicTest中，我发现情况过于复杂，使用Atomic对象已经不适合了——基本上，如果涉及多个Atomic对象，你就有可能会被强制要求放弃这种用法，转而使用更加常规的互斥（JDK文档特别声明：当对一个对象的临界更新被限制为只涉及单个变量时，只有使用Atomic对象这种方式才能工作）。但是，这个测试仍旧保留了下来，使你能够感受到Atomic对象的性能优势。

在main()中，测试是重复运行的，并且你可以要求其重复次数超过5次（默认次数）。对于每次重复，测试循环的数量都会加倍，因此你可以看到当运行次数越来越多时，这些不同的互斥在行为方面存在着怎样的差异。正如你从输出中可以看到的那样，测试结果相当惊人。对于前四次迭代，synchronized关键字看起来比使用Lock或Atomic要更高效。但是，突然间越过了门槛值之后，synchronized关键字似乎变得非常低效，而Lock和Atomic则显得大体维持着与BaseLine测试之间的比例关系，因此也就变得比synchronized关键字要高效得多。

记住，这个程序只给出了各种互斥方式之间的差异的趋势，而上面的输出也仅仅表示这些差异在我的特定环境下的特定机器上的表现。如你所见，如果自己动手试验，当所使用的线程数量不同，或者程序运行的时间更长时，在行为方面肯定会存在着明显的变化。例如，某些hotspot运行时优化会在程序运行数分钟之后被调用，但是对于服务器端程序，这段时间可能会长达数小时。

也就是说，很明显，使用Lock通常会比使用synchronized要高效许多，而且synchronized的开销看起来变化范围太大，而Lock相对比较一致。

这是否意味着你永远都不应该使用synchronized关键字呢？这里有两个因素需要考虑：首先，在SynchronizationComparisons.java中，互斥方法的方法体是非常之小的。通常，这是一个很好的习惯——只互斥那些你绝对必须互斥的部分。但是，在实际中，被互斥部分可能会比上面示例中的那些大许多，因此在这些方法体中花费的时间的百分比可能会明显大于进入和退出互斥的开销，这样也就湮灭了提高互斥速度带来的所有好处。当然，唯一了解这一点的方式是——当你在对性能调优时，应该立即——尝试各种不同的方法并观察它们造成的影响。

其次，阅读本章中的代码就会发现，很明显，synchronized关键字所产生的代码，与Lock所需的**“加锁-try/finally-解锁”**惯用法所产生的代码相比，可读性提高了很多，这就是为什么本章主要使用synchronized关键字的原因。就像我在本书其他地方提到的，代码被阅读的次数远多于被编写的次数。在编程时，与其他人交流相对于与计算机交流而言，要重要的多，因此代码的可读性至关重要。因此，以synchronized关键字入手，只有在性能调优时才替换为Lock对象这种做法，是具有实际意义的。

最后，当你在自己的并发程序中可以使用Atomic类时，这肯定非常好，但是要意识到，正如我们在SynchronizationComparisons.java中所看到的，Atomic对象只有在非常简单的情况下才有用，这些情况通常包括你只有一个要被修改的Atomic对象，并且这个对象独立于其他所有的对象。更安全的做法是：以更加传统的互斥方式入手，只有在性能方面的需求能够明确指示时，再替换为Atomic。

## 二、免锁容器
就像在第11章中所强调的，容器是所有编程中的基础工具，这其中自然也包括并发编程。出于这个原因，像Vector和Hashtablel这类早期容器具有许多synchronized方法，当它们用于非多线程的应用程序中时，便会导致不可接受的开销。在Java1.2中，新的容器类库是不同步的，并且Collections类提供了各种static的同步的装饰方法，从而来同步不同类型的容器。尽管这是一种改进，因为它使你可以选择在你的容器中是否要使用同步，但是这种开销仍旧是基于synchronized加锁机制的。Java SE5特别添加了新的容器，通过使用更灵巧的技术来消除加锁，从而提高线程安全的性能。

这些免锁容器背后的通用策略是：对容器的修改可以与读取操作同时发生，只要读取者只能看到完成修改的结果即可。修改是在容器数据结构的某个部分的一个单独的副本（有时是整个数据结构的副本）上执行的，并且这个副本在修改过程中是不可视的。只有当修改完成时，被修改的结构才会自动地与主数据结构进行交换，之后读者就可以看到这个修改了。

在CopyOnWriteArrayList中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。当修改完成时，一个原子性的操作将把新的数组换入，使得新的读取操作可以看到这个新的修改。CopyOnWriteArrayList的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出ConcurrentModificationException，因此你不必编写特殊的代码去防范这种异常，就像你以前必须做的那样。

CopyOnWriteArraySet将使用CopyOnWriteArrayList来实现其免锁行为。

ConcurrentHashMap和ConcurrentLinkedQueue使用了类似的技术，允许并发的读取和写入，但是容器中只有部分内容而不是整个容器可以被复制和修改。然而，任何修改在完成之前，读取者仍旧不能看到它们。ConcurrentHashMap不会抛出ConcurrentModificationException异常。

### 性能问题
只要你主要是从免锁容器中读取，那么它就会比其synchronized对应物快许多，因为获取和释放锁的开销被省掉了。如果需要向免锁容器中执行少量写入，那么情况仍旧如此，但是什么算“少量”？这是一个很有意思的问题。本节将介绍有关在各种不同条件下，这些容器在性能方面差异的大致概念。

我将从一个泛型框架着手，它专门用于在任何类型的容器上执行测试，包括各种Map在内，其中泛型参数C表示容器的类型：
```java
// Framework to test performance of concurrency containers.
package concurrency;
import java.util.concurrent.*;
import net.mindview.util.*;

public abstract class Tester<C> {
	static int testReps = 10;
	static int testCycles = 1000;
	static int containerSize = 1000;
	abstract C containerInitializer();
	abstract void startReadersAndWriters();
	C testContainer;
	String testId;
	int nReaders;
	int nWriters;
	volatile long readResult = 0;
	volatile long readTime = 0;
	volatile long writeTime = 0;
	CountDownLatch endLatch;
	static ExecutorService exec = Executors.newCachedThreadPool();
	Integer[] writeData;
	Tester(String testId, int nReaders, int nWriters) {
		this.testId = testId + " " + nReaders + "r " + nWriters + "w";
		this.nReaders = nReaders;
		this.nWriters = nWriters;
		writeData = Generated.array(Integer.class, 
				new RandomGenerator.Integer(), containerSize);
		for (int i = 0; i < testReps; i++) {
			runTest();
			readTime = 0;
			writeTime = 0;
		}
	}
	void runTest() {
		endLatch = new CountDownLatch(nReaders + nWriters);
		testContainer = containerInitializer();
		startReadersAndWriters();
		try {
			endLatch.await();
		} catch (InterruptedException ex) {
			System.out.println("endLatch interrupted");
		}
		System.out.printf("%-27s %14d %14d\n", testId, readTime, writeTime);
		if (readTime != 0 && writeTime != 0)
			System.out.printf("%-27s %14d\n", 
					"readTime + writeTime =", readTime + writeTime);
	}
	abstract class TestTask implements Runnable {
		abstract void test();
		abstract void putResults();
		long duration;
		public void run() {
			long startTime = System.nanoTime();
			test();
			duration = System.nanoTime() - startTime;
			synchronized (Tester.this) {
				putResults();
			}
			endLatch.countDown();
		}
	}
	public static void initMain(String[] args) {
		if (args.length > 0)
			testReps = new Integer(args[0]);
		if (args.length > 1)
			testCycles = new Integer(args[1]);
		if (args.length > 2)
			containerSize = new Integer(args[2]);
		System.out.printf("%-27s %14s %14s\n", 
				"Type", "Read time", "Write time");
	}
}
```
abstract方法containerInitializer()返回将被测试的初始化后的容器，它被存储在testContainer域中。另一个abstract方法startReadersAndWriters()启动读取者和写入者任务，它们将读取和修改待测容器。不同的测试在运行时将具有数量变化的读取者和写入者，这样就可以观察到锁竞争（针对synchronized容器而言）和写入（针对免锁容器而言）的效果。

我们向构造器提供了各种有关测试的信息（参数标识符应该是自解释的），然后它会调用runTest()方法repetitions次。runTest()将创建一个CountDownLatch（因此测试可以知道所有任务何时完成）、初始化容器，然后调用startReadersAndWriters()，并等待它们全部完成。

每个Reader和Writer类都基于TestTask，它可以度量其抽象方法test()的执行时间，然后在一个synchronized块中调用putResult()去存储度量结果。

为了使用这个框架（其中你可以识别出模版方法设计模式），我们必须让想要测试的特定类型的容器继承Tester，并提供适合的Reader和Writer类：
```java
// {Args: 1 10 10} (Fast verification check during build) 
// Rough comparison of thread-safe List performance. 
package concurrency;
import java.util.concurrent.*;
import java.util.*;
import net.mindview.util.*;

abstract class ListTest extends Tester<List<Integer>> {
	ListTest(String testId, int nReaders, int nWriters) {
		super(testId, nReaders, nWriters);
	}
	class Reader extends TestTask {
		long result = 0;
		void test() {
			for (long i = 0; i < testCycles; i++)
				for (int index = 0; index < containerSize; index++)
					result += testContainer.get(index);
		}
		void putResults() {
			readResult += result;
			readTime += duration;
		}
	}

	class Writer extends TestTask {
		void test() {
			for (long i = 0; i < testCycles; i++)
				for (int index = 0; index < containerSize; index++)
					testContainer.set(index, writeData[index]);
		}
		void putResults() {
			writeTime += duration;
		}
	}

	void startReadersAndWriters() {
		for (int i = 0; i < nReaders; i++)
			exec.execute(new Reader());
		for (int i = 0; i < nWriters; i++)
			exec.execute(new Writer());
	}
}

class SynchronizedArrayListTest extends ListTest {
	List<Integer> containerInitializer() {
		return Collections.synchronizedList(
				new ArrayList<Integer>(new CountingIntegerList(containerSize)));
	}
	SynchronizedArrayListTest(int nReaders, int nWriters) {
		super("Synched ArrayList", nReaders, nWriters);
	}
}

class CopyOnWriteArrayListTest extends ListTest {
	List<Integer> containerInitializer() {
		return new CopyOnWriteArrayList<Integer>(
				new CountingIntegerList(containerSize));
	}
	CopyOnWriteArrayListTest(int nReaders, int nWriters) {
		super("CopyOnWriteArrayList", nReaders, nWriters);
	}
}

public class ListComparisons {
	public static void main(String[] args) {
		Tester.initMain(args);
		new SynchronizedArrayListTest(10, 0);
		new SynchronizedArrayListTest(9, 1);
		new SynchronizedArrayListTest(5, 5);
		new CopyOnWriteArrayListTest(10, 0);
		new CopyOnWriteArrayListTest(9, 1);
		new CopyOnWriteArrayListTest(5, 5);
		Tester.exec.shutdown();
	}
}/*Output:
Type                             Read time     Write time
Synched ArrayList 10r 0w            990100              0
Synched ArrayList 9r 1w            1544000          36100
readTime + writeTime =             1580100
Synched ArrayList 5r 5w            1088400         748200
readTime + writeTime =             1836600
CopyOnWriteArrayList 10r 0w         480400              0
CopyOnWriteArrayList 9r 1w          165700         134700
readTime + writeTime =              300400
CopyOnWriteArrayList 5r 5w           65100        2869000
readTime + writeTime =             2934100
*///
```
在ListTest中，Reader和Writer类执行针对```List<Integer>```的具体动作。在Reader.putResults()中，duration被存储起来，result也是一样，这样可以防止这些计算被优化掉。startReadersAndWriters()被定义为创建和执行具体的Readers和Writers。

一旦创建了ListTest，它就必须被进一步继承，以覆盖containerInitializer()，从而可以创建和初始化具体的测试容器。

在main()中，你可以看到各种测试变体，它们具有不同数量的读取者和写入者。由于存在对Tester.initMain(args)的调用，所以你可以使用命令行参数来改变测试变量。

默认行是为每个测试运行10次，这有助于稳定输出，而输出是可以变化的，因为存在着诸如hotspot优化和垃圾回收这样的JVM活动。你看到的样本输出已经被编辑为只显示每个测试的最后一个迭代。从输出中可以看到，synchronzied ArrayList无论读取者和写入者的数量是多少，都具有大致相同的性能——读取者与其他读取者竞争锁的方式与写入者相同。但是，CopyOnWriteArrayList在没有写入者时，速度会快许多，并且在有5个写入者时，速度仍旧明显地快。看起来你应该尽量使用CopyOnWriteArrayList，对列表写入的影响并没有超过短期同步整个列表的影响。当然，你必须在你的具体应用中尝试这两种不同的方式，以了解到底哪个更好一些。

再次注意，这还不是测试结果绝对不变的良好的基准测试，你的结果几乎肯定是不同的。这里的目标只是让你对两种不同类型的容器的相对行为有个概念上的认识。

因为CopyOnWriteArraySet使用了CopyOnWriteArrayList，所以它的行为与此类似，在这里就不需要另外设计一个单独的测试了。

### 比较Map实现
我们可以使用相同的框架来得到synchronizedHashMap和ConcurrentHashMap在性能方面的比较结果：
```java
// {Args: 1 10 10} (Fast verification check during build)
// Rough comparison of thread-safe Map performance.
package concurrency;
import java.util.concurrent.*;
import java.util.*;
import net.mindview.util.*;

abstract class MapTest extends Tester<Map<Integer, Integer>> {
	MapTest(String testId, int nReaders, int nWriters) {
		super(testId, nReaders, nWriters);
	}
	class Reader extends TestTask {
		long result = 0;
		void test() {
			for(long i = 0; i < testCycles; i++)
				for(int index = 0; index < containerSize; index++)
					result += testContainer.get(index);
		}
		void putResults() {
			readResult += result;
			readTime += duration;
		}
	}
	class Writer extends TestTask {
		void test() {
			for(long i = 0; i < testCycles; i++)
				for(int index = 0; index < containerSize; index++)
					testContainer.put(index, writeData[index]);
		}
		void putResults() {
			writeTime += duration;
		}
	}
    void startReadersAndWriters() {
    	for(int i = 0; i < nReaders; i++)
    		exec.execute(new Reader());
    	for(int i = 0; i < nWriters; i++)
    		exec.execute(new Writer());
    }
}

class SynchronizedHashMapTest extends MapTest {
	Map<Integer, Integer> containerInitializer() {
		return Collections.synchronizedMap(
			new HashMap<Integer, Integer>(
				MapData.map(
					new CountingGenerator.Integer(), 
					new CountingGenerator.Integer(), 
					containerSize)));
	}
	SynchronizedHashMapTest(int nReaders, int nWriters) {
		super("Synched HashMap", nReaders, nWriters);
	}
}

class ConcurrentHashMapTest extends MapTest {
	Map<Integer, Integer> containerInitializer() {
		return new ConcurrentHashMap<Integer, Integer>(
		    MapData.map(
				new CountingGenerator.Integer(), 
				new CountingGenerator.Integer(), containerSize));
	}
	ConcurrentHashMapTest(int nReaders, int nWriters) {
		super("ConcurrentHashMap", nReaders, nWriters);
	}
}

public class MapComparisons {
	public static void main(String[] args) {
        Tester.initMain(args);
        new SynchronizedHashMapTest(10, 0);
        new SynchronizedHashMapTest(9, 1);
        new SynchronizedHashMapTest(5, 5);
        new ConcurrentHashMapTest(10, 0);
        new ConcurrentHashMapTest(9, 1);
        new ConcurrentHashMapTest(5, 5);
	}
} /*Output:
Type                             Read time     Write time
Synched HashMap 10r 0w             3624500              0
Synched HashMap 9r 1w              1867800          46000
readTime + writeTime =             1913800
Synched HashMap 5r 5w              1119100        1031200
readTime + writeTime =             2150300
ConcurrentHashMap 10r 0w            588200              0
ConcurrentHashMap 9r 1w             504100         126000
readTime + writeTime =              630100
ConcurrentHashMap 5r 5w             228000         590700
readTime + writeTime =              818700
*///
```
向ConcurrentHashMap添加写入者的影响甚至还不如CopyOnWriteArrayList明显，这是因为ConcurrentHashMap使用了一种不同的技术，它可以明显地最小化写入所造成的影响。

## 三、乐观加锁
尽管Atomic对象将执行像decrementAndGet()这样的原子性操作，但是某些Atomic类还允许你执行所谓的“乐观加锁”。这意味着当你执行某项计算时，实际上没有使用互斥，但是在这项计算完成，并且你准备更新这个Atomic对象时，你需要使用一个称为compareAndSet()的方法。你将旧值和新值一起提交给这个方法，如果旧值与它在Atomic对象中发现的值不一致，那么这个操作就失败——这意味着某个其他任务已经于此操作执行期间修改了这个对象。记住，我们在正常情况下将使用互斥（synchronzied或Lock）来防止多个任务同时修改一个对象，但是这里我们是“乐观的”，因为我们保持数据为未锁定状态，并希望没有任何其他任务插入修改它。所有这些又都是以性能的名义执行的——通过使用Atomic来替代synchronized或Lock，可以获得性能上的好处。

如果compareAndSet()操作失败会发生什么？这正是棘手的地方，也是你在应用这项技术时的受限之处，即只能针对能够吻合这些需求的问题。如果compareAndSet()失败，那么就必须决定做些什么，这是一个非常重要的问题，因为如果不能执行某些恢复操作，那么你就不能使用这项技术，从而必须使用传统的互斥。你可能会重试这个操作，如果在第二次成功，那么万事大吉；或者可能会忽略这次失败，直接结束——在某些仿真中，如果数据点丢失，在重要的框架中，这就是最终需要做的事情（当然，你必须很好地理解你的模型，以了解情况是否确实如此）。

考虑一个假想的仿真，它由长度为30的100000个基因构成，这可能是某种类型的遗传算法的起源。假设伴随着遗传算法的每次“进化”，都会发生某些代价高昂的计算，因此你决定使用一台多处理器机器来分布这些任务以提高性能。另外，你将使用Atomic对象而不是Lock对象来防止互斥开销（当然，一开始，你使用synchronized关键字以最简单的方式编写了代码。一旦你运行该程序，发现它太慢了，并开始应用性能调优技术，而此时你也只能写出这样的解决方案）。因为你的模型的特性，使得如果在计算过程中产生冲突，那么发现冲突的任务将直接忽略它，并不会更新它的值。下面是这个示例的代码：
```java
package concurrency;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;
import java.util.*;

public class FastSimulation {
    static final int N_ELEMENTS = 100000;
    static final int N_GENES = 30;
    static final int N_EVOLVERS = 50;
    static final AtomicInteger[][] GRID = 
    		new AtomicInteger[N_ELEMENTS][N_GENES];
    static Random rand = new Random(47);
    static class Evolver implements Runnable {
    	public void run() {
    		while(!Thread.interrupted()) {
    			// Randomly select an element to work on:
    			int element = rand.nextInt(N_ELEMENTS);
    			for(int i = 0; i < N_GENES; i++) {
    				int previous = element - 1;
    				if(previous < 0) 
    					previous = N_ELEMENTS - 1;
    				int next = element + 1;
    				if(next >= N_ELEMENTS)
    					next = 0;
    				int oldvalue = GRID[element][i].get();
    				// Perform some kind of modeling calculation:
    				int newvalue = oldvalue +
    						GRID[previous][i].get() + GRID[next][i].get();
    				newvalue /= 3;  // Average the three values
    				if(!GRID[element][i].compareAndSet(oldvalue, newvalue)) {
    					// Policy here to deal with failure. Here, we
    					// just report it and ignore it; our model
    					// will eventually deal with it.
    					System.out.println("Old value changed from " + oldvalue);
    				}
    			}
    		}
    	}
    }
	public static void main(String[] args) throws Exception {
        ExecutorService exec = Executors.newCachedThreadPool();
        for(int i = 0; i < N_ELEMENTS; i++)
        	for(int j = 0; j < N_GENES; j++)
        		GRID[i][j] = new AtomicInteger(rand.nextInt(1000));
        for(int i = 0; i < N_EVOLVERS; i++)
        	exec.execute(new Evolver());
        TimeUnit.SECONDS.sleep(5);
        exec.shutdownNow();
	}
}/* (Execute to see output) *///
```
所有元素都被置于数组内，这被认为有助于提高性能（这个假设将在一个练习中进行测试）。每个Evolver对象会用它前一个元素和后一个元素来平均它的值，如果在更新时失败，那么将直接打印这个值并继续执行。注意，在这个程序中没有出现任何互斥。

**练习39：（6）FastSimulation.java是否作出了合理的假设？试着将数组从普通的int修改为AtomicInteger，并使用Lock互斥。比较这两个版本的程序的差异。**

**答案请戳:point_right:[这里](solutions/Ex39.md)**

## 四、ReadWriteLock
ReadWriteLock对于向数据结构相对不频繁的写入，但是有多个任务要经常读取这个数据结构的这类情况进行了优化。ReadWriteLock使得你可以同时有多个读取者，只要它们都不试图写入即可。如果写锁已经被其他任务持有，那么任何读取者都不能访问，直至这个写锁被释放为止。

ReadWriteLock是否能够提高程序的性能是完全不可确定的，它取决于诸如数据被读取的频率与被修改的频率相比较的结果，读取和写入操作的时间（锁将更复杂，因此短操作并不能带来好处），有多少线程竞争以及是否在多处理器机器上运行等因素。最终，唯一可以了解ReadWriteLock是否能够给你的程序带来好处的方式就是用试验来证明：
```java
package concurrency;
import java.util.concurrent.*;
import java.util.concurrent.locks.*;
import java.util.*;

public class ReaderWriterList<T> {
    private ArrayList<T> lockedList;
    // Make the ordering fair:
    private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(true);
    public ReaderWriterList(int size, T initialValue) {
    	lockedList = new ArrayList<T>(
    			Collections.nCopies(size, initialValue));
    }
    public T set(int index, T element) {
    	Lock wlock = lock.writeLock();
    	wlock.lock();
    	try {
    		return lockedList.set(index, element);
    	} finally {
    		wlock.unlock();
    	}
    }
    public T get(int index) {
    	Lock rlock = lock.readLock();
    	rlock.lock();
    	try {
    		// Show that multiple readers
    		// may acquire the read lock:
    		if(lock.getReadLockCount() > 1) 
    			System.out.println(lock.getReadLockCount());
    		return lockedList.get(index);
    	} finally {
    		rlock.unlock();
    	}
    }
	public static void main(String[] args) throws Exception {
        new ReaderWriterListTest(30, 1);
	}
}

class ReaderWriterListTest {
	ExecutorService exec = Executors.newCachedThreadPool();
	private final static int SIZE = 100;
	private static Random rand = new Random(47);
	private ReaderWriterList<Integer> list = 
			new ReaderWriterList<Integer>(SIZE, 0);
	private class Writer implements Runnable {
		public void run() {
			try {
				for(int i = 0; i < 20; i++) {  // 2 second test
					list.set(i, rand.nextInt());
					TimeUnit.MILLISECONDS.sleep(100);
				}
			} catch(InterruptedException e) {
				// Acceptable way to exit
			}
			System.out.println("Writer finished, shutting down");
		}
	}
	private class Reader implements Runnable {
		public void run() {
			try {
				while(!Thread.interrupted()) {
					for(int i = 0; i < SIZE; i++) {
						list.get(i);
						TimeUnit.MILLISECONDS.sleep(1);
					}
				}
			} catch(InterruptedException e) {
				// Acceptable way to exit
			}
		}
	}
	public ReaderWriterListTest(int readers, int writers) {
		for(int i = 0; i < readers; i++)
			exec.execute(new Reader());
		for(int i = 0; i < writers; i++)
			exec.execute(new Writer());
	}
} /* (Execute to see output) *///
```
ReaderWriterList可以持有固定数量的任何类型的对象。你必须向构造器提供所希望的列表尺寸和组装这个列表时所用的初始对象。set()方法要获取一个写锁，以调用底层的ArrayList.set()，而get()方法要获取一个读锁，以调用底层的ArrayList.get()。另外，get()将检查是否已经有多个读取者获取了读锁，如果是，则将显示这种读取者的数量，以证明可以有多个读取者获得读锁。

为了测试ReaderWriterList，ReaderWriterListTest为```ReaderWriterList<Integer>```创建了读取者和写入者类。注意，写入者的数量远少于读取者。

如果你在JDK文档中查看ReentranReadWriteLock，就会发现还有大量的其他方法可用，涉及“公平性”和“政策性决策”等问题。这时一个相当复杂的工具，只有当你在搜索可以提高性能的方法时，才应该想到用它。你的程序的第一个草案应该使用更直观的**synchronized**（同步），并且只有在必需时再引入ReadWriteLock。

**练习40：（6）遵循ReaderWriterList.java示例，使用HashMap创建一个ReaderWriterMap。通过修改MapComparisons.java来调查它的性能。它是如何比较synchronized HashMap和ConcurrentHashMap的？**

**答案请戳:point_right:[这里](solutions/Ex40.md)**

---

### [上一节：仿真](21.8_Simulation.md)　　　　　　　　[下一节：活动对象](21.10_Active_objects.md)



